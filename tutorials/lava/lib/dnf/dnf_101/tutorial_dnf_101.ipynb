{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright (C) 2021 Intel Corporation*<br>\n",
    "*SPDX-License-Identifier: BSD-3-Clause*<br>\n",
    "*See: https://spdx.org/licenses/*\n",
    "\n",
    "---\n",
    "\n",
    "# DNF 101: Dynamic neural fields in Lava\n",
    "\n",
    "## Populations and connections\n",
    "\n",
    "Create populations of leaky integrate-and-fire (LIF) neurons.\n",
    "The `shape` argument determines the number of neurons (and their layout; see\n",
    "further below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lava.proc.lif.process import LIF\n",
    "\n",
    "\n",
    "# a one-dimensional LIF population\n",
    "population = LIF(shape=(20,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create connections between populations using the `connect()` function.\n",
    "The connectivity can be specified using a sequence of _Operations_. Here,\n",
    "every neuron from `population1` is connected to the\n",
    "corresponding neuron from `population2` with a synaptic weight of 20.\n",
    "Operations are explained in more detail below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x29dc14327f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lava.lib.dnf.connect.connect import connect\n",
    "from lava.lib.dnf.operations.operations import Weights\n",
    "\n",
    "\n",
    "population1 = LIF(shape=(20,))\n",
    "population2 = LIF(shape=(20,))\n",
    "connect(population1.s_out, population2.a_in, ops=[Weights(20)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic neural fields (DNF)\n",
    "\n",
    "### Multi-peak DNF\n",
    "\n",
    "Create dynamic neural fields (DNFs) that support multiple peaks by using the\n",
    "`MultiPeakKernel` with local excitation and mid-range inhibition. Use the\n",
    "`Convolution` operation to apply the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x29da2eb0520>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lava.lib.dnf.kernels.kernels import MultiPeakKernel\n",
    "from lava.lib.dnf.operations.operations import Convolution\n",
    "\n",
    "\n",
    "dnf = LIF(shape=(20,))\n",
    "\n",
    "kernel = MultiPeakKernel(amp_exc=25,\n",
    "                         width_exc=3,\n",
    "                         amp_inh=-15,\n",
    "                         width_inh=6)\n",
    "connect(dnf.s_out, dnf.a_in, ops=[Convolution(kernel)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selective DNF\n",
    "\n",
    "Create DNFs that are selective and only create a single peak by using the\n",
    "`SelectiveKernel` with local excitation and global inhibition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x29da2eb5f70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lava.lib.dnf.kernels.kernels import SelectiveKernel\n",
    "\n",
    "\n",
    "dnf = LIF(shape=(20,))\n",
    "\n",
    "kernel = SelectiveKernel(amp_exc=18,\n",
    "                         width_exc=3,\n",
    "                         global_inh=-15)\n",
    "connect(dnf.s_out, dnf.a_in, ops=[Convolution(kernel)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input\n",
    "\n",
    "### Spike generators\n",
    "\n",
    "To simulate spike input to a DNF, use a `RateCodeSpikeGen` Process. It\n",
    "generates spikes with a spike rate pattern that can be specified, for\n",
    "instance by using the `GaussPattern` Process. Connect the `RateCodeSpikeGen` to\n",
    " a DNF with the `connect()` function. You may change parameters of the\n",
    " `GaussPattern` during runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lava.magma.core.run_configs import Loihi1SimCfg\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "from lava.lib.dnf.inputs.gauss_pattern.process import GaussPattern\n",
    "from lava.lib.dnf.inputs.rate_code_spike_gen.process import RateCodeSpikeGen\n",
    "\n",
    "\n",
    "shape = (15,)\n",
    "\n",
    "# GaussPattern produces a pattern of spike rates\n",
    "gauss_pattern = GaussPattern(shape=shape, amplitude=100, mean=5, stddev=5)\n",
    "\n",
    "# The spike generator produces spikes based on the spike rates given\n",
    "# by the Gaussian pattern\n",
    "spike_generator = RateCodeSpikeGen(shape=shape)\n",
    "gauss_pattern.a_out.connect(spike_generator.a_in)\n",
    "\n",
    "# Connect the spike generator to a population\n",
    "population = LIF(shape=shape)\n",
    "connect(spike_generator.s_out, population.a_in, ops=[Weights(20)])\n",
    "\n",
    "# Start running the network (explained below)\n",
    "population.run(condition=RunSteps(num_steps=10),\n",
    "               run_cfg=Loihi1SimCfg(select_tag='floating_pt'))\n",
    "\n",
    "# You may change parameters of the Gaussian pattern during runtime\n",
    "gauss_pattern.amplitude = 50\n",
    "\n",
    "# Continue the run\n",
    "# ...\n",
    "\n",
    "# Stop the run to free resources\n",
    "population.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher dimensions\n",
    "\n",
    "Define DNFs and inputs over higher dimensionalities by specifying a `shape` with\n",
    "multiple entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shape = (15, 15)\n",
    "dnf = LIF(shape=shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs and kernels must match the dimensionality of the DNF; specify\n",
    "parameters that can be multi-dimensional, for example `mean` and `stddev` in\n",
    "`GaussPattern`, as vectors rather than scalars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x29dc14426a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure to specify 'mean' and 'stddev' as 2D vectors\n",
    "gauss_pattern = GaussPattern(shape=shape,\n",
    "                             amplitude=100,\n",
    "                             mean=[5, 5],\n",
    "                             stddev=[4, 4])\n",
    "spike_generator = RateCodeSpikeGen(shape=shape)\n",
    "gauss_pattern.a_out.connect(spike_generator.a_in)\n",
    "\n",
    "# Make sure to specify 'width_exc' and 'width_inh'\n",
    "# as 2D vectors\n",
    "kernel = MultiPeakKernel(amp_exc=58,\n",
    "                         width_exc=[3.8, 3.8],\n",
    "                         amp_inh=-50,\n",
    "                         width_inh=[7.5, 7.5])\n",
    "connect(dnf.s_out, dnf.a_in, ops=[Convolution(kernel)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Larger architectures\n",
    "\n",
    "### One-to-one connections\n",
    "When connecting two DNFs that have the same shape (in terms of neurons and\n",
    "dimensions), you can connect them without specifying any operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dnf1 = LIF(shape=(10,))\n",
    "dnf2 = LIF(shape=(10,))\n",
    "\n",
    "connect(dnf1.s_out, dnf2.a_in)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In that case the synaptic weight defaults to 1. If you want to set a\n",
    "homogeneous weight for all neurons, use the operation `Weights`.\n",
    "It connects each neuron in the first DNF to its (single) respective neuron\n",
    "in the second DNF with the specified weight value."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x29dc1511c70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnf1 = LIF(shape=(10,))\n",
    "dnf2 = LIF(shape=(10,))\n",
    "\n",
    "connect(dnf1.s_out, dnf2.a_in, ops=[Weights(40)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing dimensions\n",
    "When the dimensionality of the source DNF is larger than that of\n",
    "the target DNF, use the `ReduceDims` operation, specifying the indices of the\n",
    " dimensions that should be removed and how to remove them (here, by summing\n",
    " over dimension 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x29dc1464610>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lava.lib.dnf.operations.operations import ReduceDims\n",
    "from lava.lib.dnf.operations.enums import ReduceMethod\n",
    "\n",
    "\n",
    "dnf_2d = LIF(shape=(20, 10,))\n",
    "dnf_1d = LIF(shape=(20,))\n",
    "\n",
    "connect(dnf_2d.s_out,\n",
    "        dnf_1d.a_in,\n",
    "        ops=[ReduceDims(reduce_dims=1, reduce_method=ReduceMethod.SUM)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding dimensions\n",
    "When the dimensionality of the source DNF is smaller than that of the target\n",
    "DNF, use the `ExpandDims` operation, specifying the number of neurons of the\n",
    "dimensions that will be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x29dc179f5e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lava.lib.dnf.operations.operations import ExpandDims\n",
    "\n",
    "\n",
    "dnf_1d = LIF(shape=(20,))\n",
    "dnf_2d = LIF(shape=(20, 10))\n",
    "\n",
    "connect(dnf_1d.s_out, dnf_2d.a_in, ops=[ExpandDims(new_dims_shape=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reordering dimensions\n",
    "To reorder dimensions, use the `Reorder` operation, specifying the indices of the dimension in their new order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x29dc17b25e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lava.lib.dnf.operations.operations import Reorder\n",
    "\n",
    "\n",
    "dnf_1 = LIF(shape=(10, 20))\n",
    "dnf_2 = LIF(shape=(20, 10))\n",
    "\n",
    "# map dimensions (0, 1) of dnf_1 to dimensions (1, 0) of dnf_2\n",
    "connect(dnf_1.s_out, dnf_2.a_in, ops=[Reorder(order=(1, 0))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining operations\n",
    "\n",
    "All operations can be combined with each other to produce more complex\n",
    "connectivity. For instance, reordering can be combined with the `ReduceDims` or\n",
    "`ExpandDims` operation, which can again be combined with a `Weights` operation,\n",
    "as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x29dc1442ac0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnf_1d = LIF(shape=(10,))\n",
    "dnf_2d = LIF(shape=(20, 10))\n",
    "\n",
    "connect(dnf_1d.s_out, dnf_2d.a_in, ops=[ExpandDims(new_dims_shape=20),\n",
    "                                        Reorder(order=(1, 0)),\n",
    "                                        Weights(20)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Running and plotting networks\n",
    "\n",
    "Call the `run()` method on any Process in the network.\n",
    "To inspect Vars and Ports in Processes, create Monitors. Use them to probe Vars\n",
    "and Ports before running. Create plots with the probed data after running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lava.proc.monitor.process import Monitor\n",
    "\n",
    "\n",
    "shape = (15,)\n",
    "time_steps = 10\n",
    "\n",
    "# Set up a DNF\n",
    "dnf = LIF(shape=shape)\n",
    "kernel = MultiPeakKernel(amp_exc=17,\n",
    "                         width_exc=3,\n",
    "                         amp_inh=-15,\n",
    "                         width_inh=6)\n",
    "connect(dnf.s_out, dnf.a_in, ops=[Convolution(kernel)])\n",
    "\n",
    "# Set up a monitor and probe the spike output of the DNF\n",
    "monitor = Monitor()\n",
    "monitor.probe(dnf.s_out, time_steps)\n",
    "\n",
    "# Run the DNF\n",
    "dnf.run(condition=RunSteps(num_steps=time_steps),\n",
    "        run_cfg=Loihi1SimCfg(select_tag='floating_pt'))\n",
    "\n",
    "# Get probed data from monitor\n",
    "probed_data = monitor.get_data()\n",
    "\n",
    "# Stop the execution after getting the monitor's data\n",
    "dnf.stop()\n",
    "\n",
    "# Now you can plot the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}