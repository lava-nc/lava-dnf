{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Copyright (C) 2022 Intel Corporation*<br>\n",
    "*SPDX-License-Identifier: BSD-3-Clause*<br>\n",
    "*See: https://spdx.org/licenses/*\n",
    "\n",
    "---\n",
    "\n",
    "# lava-dnf 101: Overview of features\n",
    "\n",
    "## Populations and connections\n",
    "\n",
    "Create populations of leaky integrate-and-fire (LIF) neurons.\n",
    "The `shape` argument determines the number of neurons (and their layout; see\n",
    "further below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lava.proc.lif.process import LIF\n",
    "\n",
    "\n",
    "# a one-dimensional LIF population\n",
    "population = LIF(shape=(20,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create connections between populations using the `connect()` function.\n",
    "The connectivity can be specified using a sequence of _Operations_. Here,\n",
    "every neuron from `population1` is connected to the\n",
    "corresponding neuron from `population2` with a synaptic weight of 20.\n",
    "Operations are explained in more detail below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x7fe0073a3070>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lava.lib.dnf.connect.connect import connect\n",
    "from lava.lib.dnf.operations.operations import Weights\n",
    "\n",
    "\n",
    "population1 = LIF(shape=(20,))\n",
    "population2 = LIF(shape=(20,))\n",
    "connect(population1.s_out, population2.a_in, ops=[Weights(20)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dynamic neural fields (DNF)\n",
    "\n",
    "### Multi-peak DNF\n",
    "\n",
    "Create dynamic neural fields (DNFs) that support multiple peaks by using the\n",
    "`MultiPeakKernel` with local excitation and mid-range inhibition. Use the\n",
    "`Convolution` operation to apply the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x7fe00733a310>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lava.lib.dnf.kernels.kernels import MultiPeakKernel\n",
    "from lava.lib.dnf.operations.operations import Convolution\n",
    "\n",
    "\n",
    "dnf = LIF(shape=(20,))\n",
    "\n",
    "kernel = MultiPeakKernel(amp_exc=25,\n",
    "                         width_exc=3,\n",
    "                         amp_inh=-15,\n",
    "                         width_inh=6)\n",
    "connect(dnf.s_out, dnf.a_in, ops=[Convolution(kernel)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Selective DNF\n",
    "\n",
    "Create DNFs that are selective and only create a single peak by using the\n",
    "`SelectiveKernel` with local excitation and global inhibition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x7fe00733aeb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lava.lib.dnf.kernels.kernels import SelectiveKernel\n",
    "\n",
    "\n",
    "dnf = LIF(shape=(20,))\n",
    "\n",
    "kernel = SelectiveKernel(amp_exc=18,\n",
    "                         width_exc=3,\n",
    "                         global_inh=-15)\n",
    "connect(dnf.s_out, dnf.a_in, ops=[Convolution(kernel)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Input\n",
    "\n",
    "### Spike generators\n",
    "\n",
    "To simulate spike input to a DNF, use a `RateCodeSpikeGen` Process. It\n",
    "generates spikes with a spike rate pattern that can be specified, for\n",
    "instance by using the `GaussPattern` Process. Connect the `RateCodeSpikeGen` to\n",
    " a DNF with the `connect()` function. You may change parameters of the\n",
    " `GaussPattern` during runtime. \n",
    " \n",
    " Note that this example runs in simulation only. For examples that run on Loihi 2 refer to the tutorial \"DNF Regimes\" and \"Relational Networks\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lava.magma.core.run_configs import Loihi1SimCfg\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "from lava.lib.dnf.inputs.gauss_pattern.process import GaussPattern\n",
    "from lava.lib.dnf.inputs.rate_code_spike_gen.process import RateCodeSpikeGen\n",
    "\n",
    "\n",
    "shape = (15,)\n",
    "\n",
    "# GaussPattern produces a pattern of spike rates\n",
    "gauss_pattern = GaussPattern(shape=shape, amplitude=100, mean=5, stddev=5)\n",
    "\n",
    "# The spike generator produces spikes based on the spike rates given\n",
    "# by the Gaussian pattern\n",
    "spike_generator = RateCodeSpikeGen(shape=shape)\n",
    "gauss_pattern.a_out.connect(spike_generator.a_in)\n",
    "\n",
    "# Connect the spike generator to a population\n",
    "population = LIF(shape=shape)\n",
    "connect(spike_generator.s_out, population.a_in, ops=[Weights(20)])\n",
    "\n",
    "# Start running the network\n",
    "condition = RunSteps(num_steps=10)\n",
    "run_cfg = Loihi1SimCfg(select_tag='floating_pt')\n",
    "population.run(condition=condition,run_cfg=run_cfg)\n",
    "\n",
    "# You may change parameters of the Gaussian pattern during runtime\n",
    "gauss_pattern.amplitude = 50\n",
    "\n",
    "# Continue the run\n",
    "population.run(condition=condition, run_cfg=run_cfg)\n",
    "\n",
    "# Stop the run to free resources\n",
    "population.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Higher dimensions\n",
    "\n",
    "Define DNFs and inputs over higher dimensionalities by specifying a `shape` with\n",
    "multiple entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shape = (15, 15)\n",
    "dnf = LIF(shape=shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Inputs and kernels must match the dimensionality of the DNF; specify\n",
    "parameters that can be multi-dimensional, for example `mean` and `stddev` in\n",
    "`GaussPattern`, as vectors rather than scalars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x7fe00734a3a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure to specify 'mean' and 'stddev' as 2D vectors\n",
    "gauss_pattern = GaussPattern(shape=shape,\n",
    "                             amplitude=100,\n",
    "                             mean=[5, 5],\n",
    "                             stddev=[4, 4])\n",
    "spike_generator = RateCodeSpikeGen(shape=shape)\n",
    "gauss_pattern.a_out.connect(spike_generator.a_in)\n",
    "\n",
    "# Make sure to specify 'width_exc' and 'width_inh'\n",
    "# as 2D vectors\n",
    "kernel = MultiPeakKernel(amp_exc=58,\n",
    "                         width_exc=[3.8, 3.8],\n",
    "                         amp_inh=-50,\n",
    "                         width_inh=[7.5, 7.5])\n",
    "connect(dnf.s_out, dnf.a_in, ops=[Convolution(kernel)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Operations and larger architectures\n",
    "\n",
    "### One-to-one connections\n",
    "When connecting two DNFs that have the same shape (in terms of neurons and\n",
    "dimensions), you can connect them without specifying any operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x7fe0073a3a60>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnf1 = LIF(shape=(10,))\n",
    "dnf2 = LIF(shape=(10,))\n",
    "\n",
    "connect(dnf1.s_out, dnf2.a_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In that case the synaptic weight defaults to 1. If you want to set a\n",
    "homogeneous weight for all neurons, use the operation `Weights`.\n",
    "It connects each neuron in the first DNF to its (single) respective neuron\n",
    "in the second DNF with the specified weight value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x7fe031f54460>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnf1 = LIF(shape=(10,))\n",
    "dnf2 = LIF(shape=(10,))\n",
    "\n",
    "connect(dnf1.s_out, dnf2.a_in, ops=[Weights(40)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Reducing dimensions\n",
    "When the dimensionality of the source DNF is larger than that of\n",
    "the target DNF, use the `ReduceDims` operation, specifying the indices of the\n",
    " dimensions that should be removed and how to remove them (here, by summing\n",
    " over dimension 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x7fe031f651c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lava.lib.dnf.operations.operations import ReduceDims\n",
    "from lava.lib.dnf.operations.enums import ReduceMethod\n",
    "\n",
    "\n",
    "dnf_2d = LIF(shape=(20, 10))\n",
    "dnf_1d = LIF(shape=(20,))\n",
    "\n",
    "connect(dnf_2d.s_out,\n",
    "        dnf_1d.a_in,\n",
    "        ops=[ReduceDims(reduce_dims=1, reduce_method=ReduceMethod.SUM)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Expanding dimensions\n",
    "When the dimensionality of the source DNF is smaller than that of the target\n",
    "DNF, use the `ExpandDims` operation, specifying the number of neurons of the\n",
    "dimensions that will be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x7fe031f659d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lava.lib.dnf.operations.operations import ExpandDims\n",
    "\n",
    "\n",
    "dnf_1d = LIF(shape=(20,))\n",
    "dnf_2d = LIF(shape=(20, 10))\n",
    "\n",
    "connect(dnf_1d.s_out, dnf_2d.a_in, ops=[ExpandDims(new_dims_shape=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Reordering dimensions\n",
    "To reorder dimensions, use the `ReorderDims` operation, specifying the indices of the dimension in their new order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x7fe031f6cf70>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lava.lib.dnf.operations.operations import ReorderDims\n",
    "\n",
    "\n",
    "dnf_1 = LIF(shape=(10, 20))\n",
    "dnf_2 = LIF(shape=(20, 10))\n",
    "\n",
    "# map dimensions (0, 1) of dnf_1 to dimensions (1, 0) of dnf_2\n",
    "connect(dnf_1.s_out, dnf_2.a_in, ops=[ReorderDims(order=(1, 0))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Flipping dimensions\n",
    "To flip dimensions, use the `Flip` operation, specifying the indices of the dimensions that should be flipped. The operation will map the first neuron of the input population to the last of the output population, the second to the second last, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x7fe031f6c9d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lava.lib.dnf.operations.operations import Flip\n",
    "\n",
    "dnf_1 = LIF(shape=(10, 20))\n",
    "dnf_2 = LIF(shape=(10, 20))\n",
    "\n",
    "# connect the DNFs and flip the dimension of size 20\n",
    "connect(dnf_1.s_out, dnf_2.a_in, ops=[Flip(dims=(1,))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Projecting along a diagonal\n",
    "The operation `ReduceAlongDiagonal` sums the output of a higher-dimensional population of neurons along its main diagonal diagonal onto a lower-dimensional population. The operation `ExpandAlongDiagonal` does the inverse and projects a ridge of input from a lower-dimensional population into a higher-dimensional population along its main diagonal.\n",
    "They both enable building relational networks (see the dedicated\n",
    "[tutorial on relational networks](../relational_networks/tutorial_relational_networks.ipynb \"Tutorial on relational networks\"))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x7fe031f75c10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lava.lib.dnf.operations.operations import ReduceAlongDiagonal\n",
    "\n",
    "dnf_2d = LIF(shape=(40, 40))\n",
    "relational_dnf_1d = LIF(shape=(79,))  # shape=(40 * 2 - 1,)\n",
    "\n",
    "connect(dnf_2d.s_out, relational_dnf_1d.a_in, ops=[ReduceAlongDiagonal()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x7fe031f505b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lava.lib.dnf.operations.operations import ExpandAlongDiagonal\n",
    "\n",
    "relational_dnf_1d = LIF(shape=(79,))\n",
    "dnf_2d = LIF(shape=(40, 40))  # shape=((79+1)/2, (79+1)/2)\n",
    "\n",
    "\n",
    "connect(relational_dnf_1d.s_out, dnf_2d.a_in, ops=[ExpandAlongDiagonal()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Combining operations\n",
    "\n",
    "All operations can be combined with each other to produce more complex\n",
    "connectivity. For instance, reordering can be combined with the `ReduceDims` or\n",
    "`ExpandDims` operation, which can again be combined with a `Weights` operation,\n",
    "as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x7fe031f175e0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnf_1d = LIF(shape=(10,))\n",
    "dnf_2d = LIF(shape=(20, 10))\n",
    "\n",
    "connect(dnf_1d.s_out, dnf_2d.a_in, ops=[ExpandDims(new_dims_shape=20),\n",
    "                                        ReorderDims(order=(1, 0)),\n",
    "                                        Weights(20)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}