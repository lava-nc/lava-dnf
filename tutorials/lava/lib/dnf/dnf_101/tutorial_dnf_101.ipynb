{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright (C) 2021 Intel Corporation*<br>\n",
    "*SPDX-License-Identifier: BSD-3-Clause*<br>\n",
    "*See: https://spdx.org/licenses/*\n",
    "\n",
    "---\n",
    "\n",
    "# lava-dnf 101: Overview of features\n",
    "\n",
    "## Populations and connections\n",
    "\n",
    "Create populations of leaky integrate-and-fire (LIF) neurons.\n",
    "The `shape` argument determines the number of neurons (and their layout; see\n",
    "further below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lava.proc.lif.process import LIF\n",
    "\n",
    "\n",
    "# a one-dimensional LIF population\n",
    "population = LIF(shape=(20,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create connections between populations using the `connect()` function.\n",
    "The connectivity can be specified using a sequence of _Operations_. Here,\n",
    "every neuron from `population1` is connected to the\n",
    "corresponding neuron from `population2` with a synaptic weight of 20.\n",
    "Operations are explained in more detail below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x25e1e8b8f70>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lava.lib.dnf.connect.connect import connect\n",
    "from lava.lib.dnf.operations.operations import Weights\n",
    "\n",
    "\n",
    "population1 = LIF(shape=(20,))\n",
    "population2 = LIF(shape=(20,))\n",
    "connect(population1.s_out, population2.a_in, ops=[Weights(20)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic neural fields (DNF)\n",
    "\n",
    "### Multi-peak DNF\n",
    "\n",
    "Create dynamic neural fields (DNFs) that support multiple peaks by using the\n",
    "`MultiPeakKernel` with local excitation and mid-range inhibition. Use the\n",
    "`Convolution` operation to apply the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x25e7f4bf4f0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lava.lib.dnf.kernels.kernels import MultiPeakKernel\n",
    "from lava.lib.dnf.operations.operations import Convolution\n",
    "\n",
    "\n",
    "dnf = LIF(shape=(20,))\n",
    "\n",
    "kernel = MultiPeakKernel(amp_exc=25,\n",
    "                         width_exc=3,\n",
    "                         amp_inh=-15,\n",
    "                         width_inh=6)\n",
    "connect(dnf.s_out, dnf.a_in, ops=[Convolution(kernel)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selective DNF\n",
    "\n",
    "Create DNFs that are selective and only create a single peak by using the\n",
    "`SelectiveKernel` with local excitation and global inhibition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x25e1c8524c0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lava.lib.dnf.kernels.kernels import SelectiveKernel\n",
    "\n",
    "\n",
    "dnf = LIF(shape=(20,))\n",
    "\n",
    "kernel = SelectiveKernel(amp_exc=18,\n",
    "                         width_exc=3,\n",
    "                         global_inh=-15)\n",
    "connect(dnf.s_out, dnf.a_in, ops=[Convolution(kernel)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input\n",
    "\n",
    "### Spike generators\n",
    "\n",
    "To simulate spike input to a DNF, use a `RateCodeSpikeGen` Process. It\n",
    "generates spikes with a spike rate pattern that can be specified, for\n",
    "instance by using the `GaussPattern` Process. Connect the `RateCodeSpikeGen` to\n",
    " a DNF with the `connect()` function. You may change parameters of the\n",
    " `GaussPattern` during runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lava.magma.core.run_configs import Loihi1SimCfg\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "from lava.lib.dnf.inputs.gauss_pattern.process import GaussPattern\n",
    "from lava.lib.dnf.inputs.rate_code_spike_gen.process import RateCodeSpikeGen\n",
    "\n",
    "\n",
    "shape = (15,)\n",
    "\n",
    "# GaussPattern produces a pattern of spike rates\n",
    "gauss_pattern = GaussPattern(shape=shape, amplitude=100, mean=5, stddev=5)\n",
    "\n",
    "# The spike generator produces spikes based on the spike rates given\n",
    "# by the Gaussian pattern\n",
    "spike_generator = RateCodeSpikeGen(shape=shape)\n",
    "gauss_pattern.a_out.connect(spike_generator.a_in)\n",
    "\n",
    "# Connect the spike generator to a population\n",
    "population = LIF(shape=shape)\n",
    "connect(spike_generator.s_out, population.a_in, ops=[Weights(20)])\n",
    "\n",
    "# Start running the network (explained below)\n",
    "population.run(condition=RunSteps(num_steps=10),\n",
    "               run_cfg=Loihi1SimCfg(select_tag='floating_pt'))\n",
    "\n",
    "# You may change parameters of the Gaussian pattern during runtime\n",
    "gauss_pattern.amplitude = 50\n",
    "\n",
    "# Continue the run\n",
    "# ...\n",
    "\n",
    "# Stop the run to free resources\n",
    "population.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher dimensions\n",
    "\n",
    "Define DNFs and inputs over higher dimensionalities by specifying a `shape` with\n",
    "multiple entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shape = (15, 15)\n",
    "dnf = LIF(shape=shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs and kernels must match the dimensionality of the DNF; specify\n",
    "parameters that can be multi-dimensional, for example `mean` and `stddev` in\n",
    "`GaussPattern`, as vectors rather than scalars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x25e1e8d4460>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure to specify 'mean' and 'stddev' as 2D vectors\n",
    "gauss_pattern = GaussPattern(shape=shape,\n",
    "                             amplitude=100,\n",
    "                             mean=[5, 5],\n",
    "                             stddev=[4, 4])\n",
    "spike_generator = RateCodeSpikeGen(shape=shape)\n",
    "gauss_pattern.a_out.connect(spike_generator.a_in)\n",
    "\n",
    "# Make sure to specify 'width_exc' and 'width_inh'\n",
    "# as 2D vectors\n",
    "kernel = MultiPeakKernel(amp_exc=58,\n",
    "                         width_exc=[3.8, 3.8],\n",
    "                         amp_inh=-50,\n",
    "                         width_inh=[7.5, 7.5])\n",
    "connect(dnf.s_out, dnf.a_in, ops=[Convolution(kernel)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations and larger architectures\n",
    "\n",
    "### One-to-one connections\n",
    "When connecting two DNFs that have the same shape (in terms of neurons and\n",
    "dimensions), you can connect them without specifying any operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x25e1eb49070>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnf1 = LIF(shape=(10,))\n",
    "dnf2 = LIF(shape=(10,))\n",
    "\n",
    "connect(dnf1.s_out, dnf2.a_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In that case the synaptic weight defaults to 1. If you want to set a\n",
    "homogeneous weight for all neurons, use the operation `Weights`.\n",
    "It connects each neuron in the first DNF to its (single) respective neuron\n",
    "in the second DNF with the specified weight value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x25e1edd92b0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnf1 = LIF(shape=(10,))\n",
    "dnf2 = LIF(shape=(10,))\n",
    "\n",
    "connect(dnf1.s_out, dnf2.a_in, ops=[Weights(40)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing dimensions\n",
    "When the dimensionality of the source DNF is larger than that of\n",
    "the target DNF, use the `ReduceDims` operation, specifying the indices of the\n",
    " dimensions that should be removed and how to remove them (here, by summing\n",
    " over dimension 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x25e1ede60a0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lava.lib.dnf.operations.operations import ReduceDims\n",
    "from lava.lib.dnf.operations.enums import ReduceMethod\n",
    "\n",
    "\n",
    "dnf_2d = LIF(shape=(20, 10))\n",
    "dnf_1d = LIF(shape=(20,))\n",
    "\n",
    "connect(dnf_2d.s_out,\n",
    "        dnf_1d.a_in,\n",
    "        ops=[ReduceDims(reduce_dims=1, reduce_method=ReduceMethod.SUM)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding dimensions\n",
    "When the dimensionality of the source DNF is smaller than that of the target\n",
    "DNF, use the `ExpandDims` operation, specifying the number of neurons of the\n",
    "dimensions that will be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x25e1ede6b20>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lava.lib.dnf.operations.operations import ExpandDims\n",
    "\n",
    "\n",
    "dnf_1d = LIF(shape=(20,))\n",
    "dnf_2d = LIF(shape=(20, 10))\n",
    "\n",
    "connect(dnf_1d.s_out, dnf_2d.a_in, ops=[ExpandDims(new_dims_shape=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reordering dimensions\n",
    "To reorder dimensions, use the `ReorderDims` operation, specifying the indices of the dimension in their new order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x25e1edf8250>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lava.lib.dnf.operations.operations import ReorderDims\n",
    "\n",
    "\n",
    "dnf_1 = LIF(shape=(10, 20))\n",
    "dnf_2 = LIF(shape=(20, 10))\n",
    "\n",
    "# map dimensions (0, 1) of dnf_1 to dimensions (1, 0) of dnf_2\n",
    "connect(dnf_1.s_out, dnf_2.a_in, ops=[ReorderDims(order=(1, 0))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flipping dimensions\n",
    "To flip dimensions, use the `Flip` operation, specifying the indices of the dimensions that should be flipped. The operation will map the first neuron of the input population to the last of the output population, the second to the second last, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x25e1edd1760>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lava.lib.dnf.operations.operations import Flip\n",
    "\n",
    "dnf_1 = LIF(shape=(10, 20))\n",
    "dnf_2 = LIF(shape=(10, 20))\n",
    "\n",
    "# connect the DNFs and flip the dimension of size 20\n",
    "connect(dnf_1.s_out, dnf_2.a_in, ops=[Flip(dims=(1,))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projecting along a diagonal\n",
    "The operation `ReduceAlongDiagonal` sums the output of a higher-dimensional population of neurons along its main diagonal diagonal onto a lower-dimensional population. The operation `ExpandAlongDiagonal` does the inverse and projects a ridge of input from a lower-dimensional population into a higher-dimensional population along its main diagonal.\n",
    "They both enable building relational networks (see the dedicated\n",
    "[tutorial on relational networks](../relational_networks/tutorial_relational_networks.ipynb \"Tutorial on relational networks\"))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x25e1e8dd790>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lava.lib.dnf.operations.operations import ReduceAlongDiagonal\n",
    "\n",
    "dnf_2d = LIF(shape=(40, 40))\n",
    "relational_dnf_1d = LIF(shape=(79,))  # shape=(40 * 2 - 1,)\n",
    "\n",
    "connect(dnf_2d.s_out, relational_dnf_1d.a_in, ops=[ReduceAlongDiagonal()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x25e1e8c1b50>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lava.lib.dnf.operations.operations import ExpandAlongDiagonal\n",
    "\n",
    "relational_dnf_1d = LIF(shape=(79,))\n",
    "dnf_2d = LIF(shape=(40, 40))  # shape=((79+1)/2, (79+1)/2)\n",
    "\n",
    "\n",
    "connect(relational_dnf_1d.s_out, dnf_2d.a_in, ops=[ExpandAlongDiagonal()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining operations\n",
    "\n",
    "All operations can be combined with each other to produce more complex\n",
    "connectivity. For instance, reordering can be combined with the `ReduceDims` or\n",
    "`ExpandDims` operation, which can again be combined with a `Weights` operation,\n",
    "as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lava.proc.dense.process.Dense at 0x25e1edfb880>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnf_1d = LIF(shape=(10,))\n",
    "dnf_2d = LIF(shape=(20, 10))\n",
    "\n",
    "connect(dnf_1d.s_out, dnf_2d.a_in, ops=[ExpandDims(new_dims_shape=20),\n",
    "                                        ReorderDims(order=(1, 0)),\n",
    "                                        Weights(20)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Running and plotting networks\n",
    "\n",
    "Call the `run()` method on any Process in the network.\n",
    "To inspect Vars and Ports in Processes, create Monitors. Use them to probe Vars\n",
    "and Ports before running. Create plots with the probed data after running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lava.proc.monitor.process import Monitor\n",
    "\n",
    "\n",
    "shape = (15,)\n",
    "time_steps = 10\n",
    "\n",
    "# Set up a DNF\n",
    "dnf = LIF(shape=shape)\n",
    "kernel = MultiPeakKernel(amp_exc=17,\n",
    "                         width_exc=3,\n",
    "                         amp_inh=-15,\n",
    "                         width_inh=6)\n",
    "connect(dnf.s_out, dnf.a_in, ops=[Convolution(kernel)])\n",
    "\n",
    "# Set up a monitor and probe the spike output of the DNF\n",
    "monitor = Monitor()\n",
    "monitor.probe(dnf.s_out, time_steps)\n",
    "\n",
    "# Run the DNF\n",
    "dnf.run(condition=RunSteps(num_steps=time_steps),\n",
    "        run_cfg=Loihi1SimCfg(select_tag='floating_pt'))\n",
    "\n",
    "# Get probed data from monitor\n",
    "probed_data = monitor.get_data()\n",
    "\n",
    "# Stop the execution after getting the monitor's data\n",
    "dnf.stop()\n",
    "\n",
    "# Now you can plot the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}