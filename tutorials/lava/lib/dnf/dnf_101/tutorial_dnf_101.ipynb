{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNF 101: Dynamic neural fields in Lava\n",
    "\n",
    "## Basic populations and connections\n",
    "\n",
    "Create populations of leaky integrate-and-fire (LIF) neurons.\n",
    "The `shape` argument determines the number of neurons (and their layout; see\n",
    "further below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lava.proc.lif.process import LIF\n",
    "\n",
    "# a one-dimensional LIF population\n",
    "population_1d = LIF(shape=(20,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create connections between populations using the `connect()` function.\n",
    "The connectivity can be specified using a sequence of operations. Here,\n",
    "every neuron from `population1` is connected to the\n",
    "corresponding neuron from `population2` with a synaptic weight of 20.\n",
    "Operations are explained in more detail below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lava.proc.lif.process import LIF\n",
    "from lava.lib.dnf.connect.connect import connect\n",
    "from lava.lib.dnf.operations.operations import Weights\n",
    "\n",
    "population1 = LIF(shape=(20,))\n",
    "population2 = LIF(shape=(20,))\n",
    "connect(population1.s_out, population2.a_in, ops=[Weights(20)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic neural fields (DNF)\n",
    "\n",
    "### Multi-peak DNF\n",
    "\n",
    "Create dynamic neural fields (DNFs) that support multiple peaks by using the\n",
    "`MultiPeakKernel` with local excitation and mid-range inhibition. Use the\n",
    "`Convolution` operation to apply the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lava.proc.lif.process import LIF\n",
    "from lava.lib.dnf.kernels.kernels import MultiPeakKernel\n",
    "from lava.lib.dnf.operations.operations import Convolution\n",
    "from lava.lib.dnf.connect.connect import connect\n",
    "\n",
    "dnf = LIF(shape=(20,))\n",
    "\n",
    "kernel = MultiPeakKernel(amp_exc=25,\n",
    "                         width_exc=3,\n",
    "                         amp_inh=-15,\n",
    "                         width_inh=6)\n",
    "connect(dnf.s_out, dnf.a_in, [Convolution(kernel)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selective DNF\n",
    "\n",
    "Create DNFs that are selective and only create a single peak by using the\n",
    "`SelectiveKernel` with local excitation and global inhibition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lava.proc.lif.process import LIF\n",
    "from lava.lib.dnf.kernels.kernels import SelectiveKernel\n",
    "from lava.lib.dnf.operations.operations import Convolution\n",
    "from lava.lib.dnf.connect.connect import connect\n",
    "\n",
    "dnf = LIF(shape=(20,))\n",
    "\n",
    "kernel = SelectiveKernel(amp_exc=18,\n",
    "                         width_exc=3,\n",
    "                         global_inh=-15)\n",
    "connect(dnf.s_out, dnf.a_in, [Convolution(kernel)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input\n",
    "\n",
    "### Spike generators\n",
    "\n",
    "To simulate spike input to a DNF, use a `RateCodeSpikeGen` Process. It\n",
    "generates spikes with a spike rate pattern that can be specified, for\n",
    "instance by using the `GaussPattern` Process. Connect the `RateCodeSpikeGen` to\n",
    " a DNF with the `connect()` function. You may change parameters of the\n",
    " `GaussPattern` during runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lava.magma.core.run_configs import Loihi1SimCfg\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "from lava.proc.lif.process import LIF\n",
    "from lava.lib.dnf.inputs.gauss_pattern.process import GaussPattern\n",
    "from lava.lib.dnf.inputs.rate_code_spike_gen.process import RateCodeSpikeGen\n",
    "from lava.lib.dnf.operations.operations import Weights\n",
    "from lava.lib.dnf.connect.connect import connect\n",
    "\n",
    "shape = (15,)\n",
    "# produces a pattern of spike rates for the spike generator\n",
    "gauss_pattern = GaussPattern(shape=shape, amplitude=100, mean=5, stddev=5)\n",
    "# produces spikes based on the given spike rates\n",
    "spike_generator = RateCodeSpikeGen(shape=shape)\n",
    "gauss_pattern.a_out.connect(spike_generator.a_in)\n",
    "\n",
    "# connect spike generator to a population\n",
    "dnf = LIF(shape=shape)\n",
    "connect(spike_generator.s_out, dnf.a_in, [Weights(20)])\n",
    "\n",
    "# start running the network (explained below)\n",
    "dnf.run(condition=RunSteps(num_steps=10),\n",
    "                  run_cfg=Loihi1SimCfg(select_sub_proc_model=True))\n",
    "\n",
    "gauss_pattern.amplitude = 50  # you may change the parameters during runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher dimensions\n",
    "\n",
    "Define DNFs and inputs over higher dimensionalities by specifying a `shape` with\n",
    "multiple entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shape = (15, 15)\n",
    "dnf = LIF(shape=shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs and kernels must match the dimensionality of the DNF; specify\n",
    "parameters such as `width_exc` as vectors rather than scalars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gauss_pattern = GaussPattern(shape=shape,\n",
    "                             amplitude=100,\n",
    "                             mean=[5, 5],\n",
    "                             stddev=[4, 4])\n",
    "spike_generator = RateCodeSpikeGen(shape=shape)\n",
    "gauss_pattern.a_out.connect(spike_generator.a_in)\n",
    "\n",
    "kernel = MultiPeakKernel(amp_exc=58,\n",
    "                         width_exc=[3.8, 3.8],\n",
    "                         amp_inh=-50,\n",
    "                         width_inh=[7.5, 7.5])\n",
    "connect(dnf.s_out, dnf.a_in, [Convolution(kernel)])\n",
    "\n",
    "connect(spike_generator.s_out, dnf.a_in, [Weights(20)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Larger architectures\n",
    "\n",
    "### One-to-one connections\n",
    "When connecting two DNFs that have the same shape (in terms of neurons and\n",
    "dimensions), use the operation `Weights`. It connects each neuron in the\n",
    "first DNF to its (single) respective neuron in the second DNF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dnf1 = LIF(shape=(10,))\n",
    "dnf2 = LIF(shape=(10,))\n",
    "\n",
    "connect(dnf1.s_out, dnf2.a_in, [Weights(40)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing dimensions\n",
    "When the dimensionality of the source DNF is larger than that of\n",
    "the target DNF, use the `ReduceDims` operation, specifying the indices of the\n",
    " dimensions that should be removed and how to remove them (here, by summing\n",
    " over dimension 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lava.lib.dnf.operations.operations import ReduceDims\n",
    "from lava.lib.dnf.operations.enums import ReduceMethod\n",
    "\n",
    "dnf_2d = LIF(shape=(20, 10,))\n",
    "dnf_1d = LIF(shape=(20,))\n",
    "\n",
    "connect(dnf_2d.s_out,\n",
    "        dnf_1d.a_in,\n",
    "        [ReduceDims(reduce_dims=1, reduce_method=ReduceMethod.SUM)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding dimensions\n",
    "When the dimensionality of the source DNF is smaller than that of the target\n",
    "DNF, use the `ExpandDims` operation, specifying the number of neurons of the\n",
    "dimensions that will be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lava.lib.dnf.operations.operations import ExpandDims\n",
    "\n",
    "dnf_1d = LIF(shape=(20,))\n",
    "dnf_2d = LIF(shape=(20, 10))\n",
    "\n",
    "connect(dnf_1d.s_out, dnf_2d.a_in, [ExpandDims(new_dims_shape=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reordering dimensions\n",
    "To reorder dimensions, use the `Reorder` operation, specifying the indices of the dimension in their new order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lava.lib.dnf.operations.operations import Reorder\n",
    "\n",
    "dnf_1 = LIF(shape=(10, 20))\n",
    "dnf_2 = LIF(shape=(20, 10))\n",
    "\n",
    "# map dimensions (0, 1) of dnf_1 to dimensions (1, 0) of dnf_2\n",
    "connect(dnf_1.s_out, dnf_2.a_in, [Reorder(order=(1, 0))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All operations can be combined with each other to produce more complex\n",
    "connectivity. For instance, reordering can be combined with the `ReduceDims` or\n",
    "`ExpandDims` operation, as shown below. And that can again be combined with a\n",
    " `Weights` operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dnf_1d = LIF(shape=(10,))\n",
    "dnf_2d = LIF(shape=(20, 10))\n",
    "\n",
    "connect(dnf_1d.s_out, dnf_2d.a_in, [ExpandDims(new_dims_shape=20),\n",
    "                                    Reorder(order=(1, 0)),\n",
    "                                    Weights(20)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Running and plotting networks\n",
    "\n",
    "Call the `run()` method, specifying the number of time steps to run for and the\n",
    "backend the model should run on. To enable plots, create Monitors, use them to probe Vars\n",
    "and Ports before running, and create plots with the probed data after running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lava.proc.monitor.process import Monitor\n",
    "from lava.magma.core.run_configs import Loihi1SimCfg\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "\n",
    "from lava.proc.lif.process import LIF\n",
    "from lava.lib.dnf.inputs.rate_code_spike_gen.process import RateCodeSpikeGen\n",
    "from lava.lib.dnf.operations.operations import Weights, Convolution\n",
    "from lava.lib.dnf.kernels.kernels import MultiPeakKernel\n",
    "from lava.lib.dnf.connect.connect import connect\n",
    "\n",
    "shape = (15,)\n",
    "time_steps = 10\n",
    "\n",
    "# Set up a DNF with a multi-peak kernel\n",
    "dnf = LIF(shape=shape)\n",
    "kernel = MultiPeakKernel(amp_exc=17,\n",
    "                         width_exc=3,\n",
    "                         amp_inh=-15,\n",
    "                         width_inh=6)\n",
    "#connect(dnf.s_out, dnf.a_in, [Convolution(kernel)])\n",
    "\n",
    "# Set up a monitor and probe the spike output of the DNF\n",
    "monitor = Monitor()\n",
    "monitor.probe(dnf.s_out, time_steps)\n",
    "\n",
    "# Run the net\n",
    "dnf.run(condition=RunSteps(num_steps=time_steps),\n",
    "        run_cfg=Loihi1SimCfg(select_sub_proc_model=True))\n",
    "\n",
    "# Get probed data from monitor\n",
    "probed_data = monitor.get_data()\n",
    "\n",
    "# Stop the execution after getting the monitor's data\n",
    "dnf.stop()\n",
    "\n",
    "# Now you can plot the data. See examples below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNF instabilities\n",
    "\n",
    "The following examples demonstrate the detection instability, the selection\n",
    "instability, and the working memory regime with one-dimensional DNFs.\n",
    "\n",
    "### Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from lava.proc.monitor.process import Monitor\n",
    "from lava.magma.core.run_configs import Loihi1SimCfg\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "\n",
    "from lava.proc.lif.process import LIF\n",
    "from lava.lib.dnf.inputs.gauss_pattern.process import GaussPattern\n",
    "from lava.lib.dnf.inputs.rate_code_spike_gen.process import RateCodeSpikeGen\n",
    "from lava.lib.dnf.operations.operations import Weights, Convolution\n",
    "from lava.lib.dnf.kernels.kernels import MultiPeakKernel\n",
    "from lava.lib.dnf.connect.connect import connect\n",
    "\n",
    "from utils import plot_1d\n",
    "\n",
    "\n",
    "shape = (15,)\n",
    "time_steps = 600\n",
    "\n",
    "# Set up spike generator 1\n",
    "gauss_pattern_1 = GaussPattern(shape=shape,\n",
    "                               amplitude=0,\n",
    "                               mean=11.25,\n",
    "                               stddev=2.25)\n",
    "spike_generator_1 = RateCodeSpikeGen(shape=shape)\n",
    "gauss_pattern_1.a_out.connect(spike_generator_1.a_in)\n",
    "\n",
    "# Set up spike generator 2\n",
    "gauss_pattern_2 = GaussPattern(shape=shape,\n",
    "                               amplitude=0,\n",
    "                               mean=3.75,\n",
    "                               stddev=2.25)\n",
    "spike_generator_2 = RateCodeSpikeGen(shape=shape)\n",
    "gauss_pattern_2.a_out.connect(spike_generator_2.a_in)\n",
    "\n",
    "# DNF with multi-peak kernel\n",
    "dnf = LIF(shape=shape, du=409, dv=2047, threshold=200)\n",
    "kernel = MultiPeakKernel(amp_exc=82,\n",
    "                         width_exc=3.75,\n",
    "                         amp_inh=-70,\n",
    "                         width_inh=7.5)\n",
    "#connect(dnf.s_out, dnf.a_in, [Convolution(kernel)])\n",
    "\n",
    "# Connect spike input to DNF\n",
    "connect(spike_generator_1.s_out, dnf.a_in, [Weights(20)])\n",
    "connect(spike_generator_2.s_out, dnf.a_in, [Weights(20)])\n",
    "\n",
    "# Set up monitors\n",
    "monitor_dnf = Monitor()\n",
    "monitor_dnf.probe(target=dnf.s_out, num_steps=time_steps)\n",
    "monitor_input1 = Monitor()\n",
    "monitor_input1.probe(spike_generator_1.s_out, time_steps)\n",
    "monitor_input2 = Monitor()\n",
    "monitor_input2.probe(spike_generator_2.s_out, time_steps)\n",
    "\n",
    "# Run the network and make changes to spike inputs over time\n",
    "condition = RunSteps(num_steps=100)\n",
    "run_cfg = Loihi1SimCfg(select_sub_proc_model=True)\n",
    "spike_generator_1.run(condition=condition, run_cfg=run_cfg)\n",
    "gauss_pattern_1.amplitude = 2300\n",
    "gauss_pattern_2.amplitude = 2300\n",
    "spike_generator_1.run(condition=condition, run_cfg=run_cfg)\n",
    "gauss_pattern_1.amplitude = 11200\n",
    "gauss_pattern_2.amplitude = 11200\n",
    "spike_generator_1.run(condition=condition, run_cfg=run_cfg)\n",
    "gauss_pattern_1.amplitude = 2300\n",
    "gauss_pattern_2.amplitude = 2300\n",
    "spike_generator_1.run(condition=RunSteps(num_steps=200), run_cfg=run_cfg)\n",
    "gauss_pattern_1.amplitude = 0\n",
    "gauss_pattern_2.amplitude = 0\n",
    "spike_generator_1.run(condition=condition, run_cfg=run_cfg)\n",
    "\n",
    "# Get probed data from monitors\n",
    "data_dnf = monitor_dnf.get_data()[dnf.name][dnf.s_out.name]\n",
    "data_input1 = monitor_input1.get_data()[spike_generator_1.name][spike_generator_1.s_out.name]\n",
    "data_input2 = monitor_input2.get_data()[spike_generator_2.name][spike_generator_2.s_out.name]\n",
    "\n",
    "# Stop the execution of the network\n",
    "spike_generator_1.stop()\n",
    "\n",
    "# Plot the probed data\n",
    "plot_1d(data_dnf,\n",
    "        data_input1,\n",
    "        data_input2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lava.proc.monitor.process import Monitor\n",
    "from lava.magma.core.run_configs import Loihi1SimCfg\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "\n",
    "from lava.proc.lif.process import LIF\n",
    "from lava.lib.dnf.inputs.gauss_pattern.process import GaussPattern\n",
    "from lava.lib.dnf.inputs.rate_code_spike_gen.process import RateCodeSpikeGen\n",
    "from lava.lib.dnf.operations.operations import Weights, Convolution\n",
    "from lava.lib.dnf.kernels.kernels import SelectiveKernel\n",
    "from lava.lib.dnf.connect.connect import connect\n",
    "\n",
    "from utils import plot_1d\n",
    "\n",
    "\n",
    "shape = (15,)\n",
    "time_steps = 700\n",
    "\n",
    "# Set up spike generator 1\n",
    "gauss_pattern_1 = GaussPattern(shape=shape,\n",
    "                               amplitude=0,\n",
    "                               mean=11.25,\n",
    "                               stddev=2.25)\n",
    "spike_generator_1 = RateCodeSpikeGen(shape=shape)\n",
    "gauss_pattern_1.a_out.connect(spike_generator_1.a_in)\n",
    "\n",
    "# Set up spike generator 2\n",
    "gauss_pattern_2 = GaussPattern(shape=shape,\n",
    "                               amplitude=0,\n",
    "                               mean=3.75,\n",
    "                               stddev=2.25)\n",
    "spike_generator_2 = RateCodeSpikeGen(shape=shape)\n",
    "gauss_pattern_2.a_out.connect(spike_generator_2.a_in)\n",
    "\n",
    "# DNF with multi-peak kernel\n",
    "dnf = LIF(shape=shape, du=409, dv=2047, threshold=200)\n",
    "kernel = SelectiveKernel(amp_exc=18,\n",
    "                         width_exc=2.25,\n",
    "                         global_inh=-15)\n",
    "#connect(dnf.s_out, dnf.a_in, [Convolution(kernel)])\n",
    "\n",
    "# Connect spike input to DNF\n",
    "connect(spike_generator_1.s_out, dnf.a_in, [Weights(30)])\n",
    "connect(spike_generator_2.s_out, dnf.a_in, [Weights(30)])\n",
    "\n",
    "# Set up monitors\n",
    "monitor_dnf = Monitor()\n",
    "monitor_dnf.probe(target=dnf.s_out, num_steps=time_steps)\n",
    "monitor_input1 = Monitor()\n",
    "monitor_input1.probe(spike_generator_1.s_out, time_steps)\n",
    "monitor_input2 = Monitor()\n",
    "monitor_input2.probe(spike_generator_2.s_out, time_steps)\n",
    "\n",
    "# Run the network and make changes to spike inputs over time\n",
    "run_cfg = Loihi1SimCfg(select_sub_proc_model=True)\n",
    "dnf.run(condition=RunSteps(num_steps=99), run_cfg=run_cfg)\n",
    "gauss_pattern_1.amplitude = 10000\n",
    "dnf.run(condition=RunSteps(num_steps=1), run_cfg=run_cfg)\n",
    "gauss_pattern_2.amplitude = 10000\n",
    "dnf.run(condition=RunSteps(num_steps=100), run_cfg=run_cfg)\n",
    "gauss_pattern_1.amplitude = 0\n",
    "dnf.run(condition=RunSteps(num_steps=100), run_cfg=run_cfg)\n",
    "gauss_pattern_1.amplitude = 10000\n",
    "dnf.run(condition=RunSteps(num_steps=100), run_cfg=run_cfg)\n",
    "gauss_pattern_2.amplitude = 0\n",
    "dnf.run(condition=RunSteps(num_steps=100), run_cfg=run_cfg)\n",
    "gauss_pattern_2.amplitude = 10000\n",
    "dnf.run(condition=RunSteps(num_steps=100), run_cfg=run_cfg)\n",
    "gauss_pattern_1.amplitude = 0\n",
    "gauss_pattern_2.amplitude = 0\n",
    "dnf.run(condition=RunSteps(num_steps=100), run_cfg=run_cfg)\n",
    "\n",
    "# Get probed data from monitors\n",
    "data_dnf = monitor_dnf.get_data()[dnf.name][dnf.s_out.name]\n",
    "data_input1 = monitor_input1.get_data()[spike_generator_1.name][spike_generator_1.s_out.name]\n",
    "data_input2 = monitor_input2.get_data()[spike_generator_2.name][spike_generator_2.s_out.name]\n",
    "\n",
    "# Stop the execution of the network\n",
    "dnf.stop()\n",
    "\n",
    "# Plot the probed data\n",
    "plot_1d(data_dnf,\n",
    "        data_input1,\n",
    "        data_input2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lava.proc.monitor.process import Monitor\n",
    "from lava.magma.core.run_configs import Loihi1SimCfg\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "\n",
    "from lava.proc.lif.process import LIF\n",
    "from lava.lib.dnf.inputs.gauss_pattern.process import GaussPattern\n",
    "from lava.lib.dnf.inputs.rate_code_spike_gen.process import RateCodeSpikeGen\n",
    "from lava.lib.dnf.operations.operations import Weights, Convolution\n",
    "from lava.lib.dnf.kernels.kernels import MultiPeakKernel\n",
    "from lava.lib.dnf.connect.connect import connect\n",
    "\n",
    "from utils import plot_1d\n",
    "\n",
    "\n",
    "shape = (15,)\n",
    "time_steps = 500\n",
    "\n",
    "# Set up spike generator 1\n",
    "gauss_pattern_1 = GaussPattern(shape=shape,\n",
    "                               amplitude=0,\n",
    "                               mean=11.25,\n",
    "                               stddev=2.25)\n",
    "spike_generator_1 = RateCodeSpikeGen(shape=shape)\n",
    "gauss_pattern_1.a_out.connect(spike_generator_1.a_in)\n",
    "\n",
    "# Set up spike generator 2\n",
    "gauss_pattern_2 = GaussPattern(shape=shape,\n",
    "                               amplitude=0,\n",
    "                               mean=3.75,\n",
    "                               stddev=2.25)\n",
    "spike_generator_2 = RateCodeSpikeGen(shape=shape)\n",
    "gauss_pattern_2.a_out.connect(spike_generator_2.a_in)\n",
    "\n",
    "# DNF with multi-peak kernel\n",
    "dnf = LIF(shape=shape, du=409, dv=2047, threshold=200)\n",
    "kernel = MultiPeakKernel(amp_exc=30,\n",
    "                         width_exc=2.5,\n",
    "                         amp_inh=-18,\n",
    "                         width_inh=4.5)\n",
    "#connect(dnf.s_out, dnf.a_in, [Convolution(kernel)])\n",
    "\n",
    "# Connect spike input to DNF\n",
    "connect(spike_generator_1.s_out, dnf.a_in, [Weights(20)])\n",
    "connect(spike_generator_2.s_out, dnf.a_in, [Weights(20)])\n",
    "\n",
    "# Set up monitors\n",
    "monitor_dnf = Monitor()\n",
    "monitor_dnf.probe(target=dnf.s_out, num_steps=time_steps)\n",
    "monitor_input1 = Monitor()\n",
    "monitor_input1.probe(spike_generator_1.s_out, time_steps)\n",
    "monitor_input2 = Monitor()\n",
    "monitor_input2.probe(spike_generator_2.s_out, time_steps)\n",
    "\n",
    "# Run the network and make changes to spike inputs over time\n",
    "condition = RunSteps(num_steps=100)\n",
    "run_cfg = Loihi1SimCfg(select_sub_proc_model=True)\n",
    "dnf.run(condition=condition, run_cfg=run_cfg)\n",
    "gauss_pattern_1.amplitude = 2300\n",
    "gauss_pattern_2.amplitude = 2300\n",
    "dnf.run(condition=condition, run_cfg=run_cfg)\n",
    "gauss_pattern_1.amplitude = 11200\n",
    "gauss_pattern_2.amplitude = 11200\n",
    "dnf.run(condition=condition, run_cfg=run_cfg)\n",
    "gauss_pattern_1.amplitude = 2300\n",
    "gauss_pattern_2.amplitude = 2300\n",
    "dnf.run(condition=condition, run_cfg=run_cfg)\n",
    "gauss_pattern_1.amplitude = 0\n",
    "gauss_pattern_2.amplitude = 0\n",
    "dnf.run(condition=condition, run_cfg=run_cfg)\n",
    "\n",
    "# Get probed data from monitors\n",
    "data_dnf = monitor_dnf.get_data()[dnf.name][dnf.s_out.name]\n",
    "data_input1 = monitor_input1.get_data()[spike_generator_1.name][spike_generator_1.s_out.name]\n",
    "data_input2 = monitor_input2.get_data()[spike_generator_2.name][spike_generator_2.s_out.name]\n",
    "\n",
    "# Stop the execution of the network\n",
    "dnf.stop()\n",
    "\n",
    "# Plot the probed data\n",
    "plot_1d(data_dnf,\n",
    "        data_input1,\n",
    "        data_input2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
